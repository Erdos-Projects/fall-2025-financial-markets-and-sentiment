{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840e0318",
   "metadata": {},
   "source": [
    "Step 1: Define Social Media Spikes\n",
    "Identify spike days/weeks/months where social media post volume exceeds the rolling historical mean by more than two standard deviations, indicating statistically significant bursts of attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cefea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Spikes:\n",
      "            date      company  all_keywords_mentions\n",
      "27    2024-08-28         AT&T                   2621\n",
      "32    2024-09-02         AT&T                   4830\n",
      "69    2024-10-09         AT&T                   4882\n",
      "77    2024-10-17         AT&T                   4832\n",
      "78    2024-10-18         AT&T                   4991\n",
      "...          ...          ...                    ...\n",
      "18142 2025-06-03  Wells Fargo                     71\n",
      "18143 2025-06-04  Wells Fargo                    241\n",
      "18171 2025-07-02  Wells Fargo                     77\n",
      "18173 2025-07-04  Wells Fargo                     91\n",
      "18184 2025-07-15  Wells Fargo                    141\n",
      "\n",
      "[1492 rows x 3 columns]\n",
      "\n",
      "Weekly Spikes:\n",
      "           date      company  all_keywords_mentions\n",
      "5    2024-09-08         AT&T                  24609\n",
      "7    2024-09-22         AT&T                  30778\n",
      "14   2024-11-10         AT&T                  32763\n",
      "15   2024-11-17         AT&T                  37023\n",
      "16   2024-11-24         AT&T                  38387\n",
      "...         ...          ...                    ...\n",
      "2621 2025-01-19  Wells Fargo                    505\n",
      "2630 2025-03-23  Wells Fargo                    525\n",
      "2631 2025-03-30  Wells Fargo                    563\n",
      "2636 2025-05-04  Wells Fargo                    551\n",
      "2641 2025-06-08  Wells Fargo                    652\n",
      "\n",
      "[398 rows x 3 columns]\n",
      "\n",
      "Monthly Spikes:\n",
      "          date             company  all_keywords_mentions\n",
      "18  2025-02-28              AbbVie                    220\n",
      "20  2025-04-30              AbbVie                    289\n",
      "21  2025-05-31              AbbVie                    318\n",
      "23  2025-07-31              AbbVie                    450\n",
      "58  2025-06-30     Bank of America                   6468\n",
      "69  2025-05-31              Boeing                  50827\n",
      "150 2025-02-28               Cisco                   2173\n",
      "174 2025-02-28             Comcast                   4425\n",
      "246 2025-02-28       Goldman Sachs                   8106\n",
      "307 2025-03-31               Intel                  27792\n",
      "355 2025-03-31  Marathon Petroleum                   1254\n",
      "377 2025-01-31                Meta                 269928\n",
      "389 2025-01-31           Microsoft                  50940\n",
      "413 2025-01-31              Nvidia                  26116\n",
      "436 2024-12-31              Pfizer                   2488\n",
      "472 2024-12-31           Starbucks                  17332\n",
      "498 2025-02-28               Tesla                 255432\n",
      "499 2025-03-31               Tesla                 290416\n",
      "532 2024-12-31        UnitedHealth                  52068\n",
      "546 2025-02-28             Verizon                   6054\n",
      "557 2025-01-31           Walgreens                   6615\n",
      "592 2024-12-31         Wells Fargo                   1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thisu\\AppData\\Local\\Temp\\ipykernel_15740\\2804847374.py:37: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df_monthly = df.set_index('date').groupby('company')['all_keywords_mentions'].resample('M').sum().reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('bluesky_merged_mentions.csv')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assume df is your DataFrame already sorted and with a datetime 'date' column\n",
    "\n",
    "# Ensure date is datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['company', 'date'])\n",
    "\n",
    "# Define functions to calculate rolling stats and flags for spikes\n",
    "\n",
    "def flag_spikes(df, window_size, count_col, flag_col):\n",
    "    \"\"\"Calculate rolling mean and std, then flag spikes above mean + 1.5*std\"\"\"\n",
    "    rolling_mean = df.groupby('company')[count_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    rolling_std = df.groupby('company')[count_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).std().fillna(0))\n",
    "    df[flag_col] = df[count_col] > (rolling_mean + 1.5 * rolling_std)\n",
    "    return df\n",
    "\n",
    "# 1. Daily counts vs 7-day rolling mean/std for spike detection\n",
    "df = flag_spikes(df, 7, 'all_keywords_mentions', 'daily_spike')\n",
    "\n",
    "daily_spikes = df[df['daily_spike']][['date', 'company', 'all_keywords_mentions']]\n",
    "\n",
    "# 2. Weekly counts need aggregation first\n",
    "df_weekly = df.set_index('date').groupby('company')['all_keywords_mentions'].resample('W').sum().reset_index()\n",
    "\n",
    "# Flag weekly spikes using 21-day rolling window (3 weeks ~ 3 data points)\n",
    "df_weekly = df_weekly.sort_values(['company', 'date'])\n",
    "df_weekly = flag_spikes(df_weekly, 21, 'all_keywords_mentions', 'weekly_spike')\n",
    "\n",
    "weekly_spikes = df_weekly[df_weekly['weekly_spike']][['date', 'company', 'all_keywords_mentions']]\n",
    "\n",
    "# 3. Monthly counts similarly\n",
    "df_monthly = df.set_index('date').groupby('company')['all_keywords_mentions'].resample('M').sum().reset_index()\n",
    "\n",
    "# Flag monthly spikes using 60-day rolling window - approximate with a 2-month rolling window (2 data points)\n",
    "# Since monthly data is monthly, 2-month â‰ˆ 2-data point rolling window\n",
    "df_monthly = df_monthly.sort_values(['company', 'date'])\n",
    "df_monthly = flag_spikes(df_monthly, 30, 'all_keywords_mentions', 'monthly_spike')\n",
    "\n",
    "monthly_spikes = df_monthly[df_monthly['monthly_spike']][['date', 'company', 'all_keywords_mentions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccda1d4",
   "metadata": {},
   "source": [
    "Step 2: Estimate Post-Spike Returns and Volatility\n",
    "\n",
    "To estimate log returns, use the ??????\n",
    "To estimate weekly volatility, use the average weekly volatility for the previous 5 days.\n",
    "To estimate monthly volatility, use the average monthly volatility for the previous 21 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0010d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c91f2953",
   "metadata": {},
   "source": [
    "Step 3: Compare realized volatility/returns with estimated returns/volatility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62152d48",
   "metadata": {},
   "source": [
    "Step 4: Regress abnormal returns and abnormal volatility on social media spike indicators controlling for market index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
