{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atproto import Client\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Iterable, Optional\n",
    "import os, csv, time, requests\n",
    "\n",
    "# ---------- CONFIG / LOGIN ----------\n",
    "client = Client()\n",
    "client.login(\"cyberhamdi.bsky.social\", \"rvz3duEuajQwa4N\")  # for production, use env vars\n",
    "\n",
    "# Where to save results (macOS)\n",
    "SAVE_DIR = \"/Users/nihan/Desktop/bluesky\"\n",
    "\n",
    "# HTTP fallback base (public AppView)\n",
    "APPVIEW_BASE = \"https://public.api.bsky.app\"\n",
    "\n",
    "# ---------- COMPANIES & ALIASES ----------\n",
    "fortune_20 = {\n",
    "    1: \"Walmart\", 2: \"Amazon\", 3: \"Apple\", 4: \"CVS\", 5: \"Tesla\",\n",
    "    6: \"Google\", 7: \"Meta\", 8: \"JPMorgan\", 9: \"Costco\", 10: \"Kroger\",\n",
    "    11: \"Walgreens\", 12: \"Target\", 13: \"UPS\", 14: \"Centene\", 15: \"Cigna\",\n",
    "    16: \"Microsoft\", 17: \"Verizon\", 18: \"IBM\", 19: \"UnitedHealth\", 20: \"ExxonMobil\",\n",
    "    21: \"McKesson\", 22: \"Chevron\", 23: \"Cardinal Health\", 24: \"Home Depot\", 25: \"Walgreens Boots Alliance\",\n",
    "    26: \"Marathon Petroleum\", 27: \"Elevance Health\", 28: \"Ford\", 29: \"AmerisourceBergen\", 30: \"Dell Technologies\",\n",
    "    31: \"General Motors\", 32: \"Nvidia\", 33: \"Pfizer\", 34: \"Procter & Gamble\", 35: \"Comcast\",\n",
    "    36: \"Johnson & Johnson\", 37: \"Wells Fargo\", 38: \"Bank of America\", 39: \"AbbVie\", 40: \"Caterpillar\",\n",
    "    41: \"Cisco\", 42: \"AT&T\", 43: \"PepsiCo\", 44: \"Intel\", 45: \"The Walt Disney Company\",\n",
    "    46: \"Boeing\", 47: \"Goldman Sachs\", 48: \"Morgan Stanley\", 49: \"Honeywell\", 50: \"Salesforce\"\n",
    "}\n",
    "\n",
    "COMPANIES = list(fortune_20.values())\n",
    "\n",
    "# Add this dict (aliases + ticker forms). Multi-word terms are auto-quoted by your _normalize_term.\n",
    "COMPANY_ALIASES = {\n",
    "    \"Walmart\": [\n",
    "        \"Walmart\", \"#Walmart\", \"WMT\", \"$WMT\", \"Doug McMillon\"\n",
    "    ],\n",
    "    \"Amazon\": [\n",
    "        \"Amazon\", \"AMZN\", \"$AMZN\", \"#AMZN\", \"Amazon.com\", \"Andy Jassy\", \"Jeff Bezos\"\n",
    "    ],\n",
    "    \"Apple\": [\n",
    "        \"Apple\", \"AAPL\", \"$AAPL\", \"#AAPL\", \"Apple Inc\", \"Tim Cook\"\n",
    "    ],\n",
    "    \"CVS\": [\n",
    "        \"CVS\", \"CVS Health\", \"CVS Pharmacy\", \"CVS Health Corp\", \"CVS Health Corporation\", \"$CVS\", \"#CVS\", \"CVS\", \"David Joyner\"\n",
    "    ],\n",
    "    \"Tesla\": [\n",
    "        \"Tesla\", \"TSLA\", \"$TSLA\", \"#TSLA\", \"Tesla Motors\", \"Elon Musk\"\n",
    "    ],\n",
    "    \"Google\": [\n",
    "        \"Google\", \"Alphabet Inc\", \"GOOGL\", \"$GOOGL\", \"#GOOGL\", \"Sundar Pichai\"\n",
    "    ],\n",
    "    \"Meta\": [\n",
    "        \"Meta\", \"Meta Platforms\", \"META\", \"$META\", \"#META\", \"Facebook\", \"Mark Zuckerberg\"\n",
    "    ],\n",
    "    \"JPMorgan\": [\n",
    "        \"JPMorgan\", \"JP Morgan\", \"JPMorgan Chase\", \"JPMorgan Chase & Co.\", \"JPM\", \"$JPM\", \"#JPM\", \"Chase\", \"#Chase\", \"Jamie Dimon\"\n",
    "    ],\n",
    "    \"Costco\": [\n",
    "        \"Costco\", \"Costco Wholesale\", \"COST\", \"$COST\", \"Ron Vachris\"\n",
    "    ],\n",
    "    \"Kroger\": [\n",
    "        \"Kroger\", \"The Kroger Co.\", \"KR\", \"$KR\", \"Rodney McMullen\"\n",
    "    ],\n",
    "    \"Walgreens\": [\n",
    "        \"Walgreens\", \"WBA\", \"$WBA\", \"Tim Wentworth\"\n",
    "    ],\n",
    "    \"Target\": [\n",
    "        \"Target\", \"TGT\", \"$TGT\", \"Brian Cornell\"\n",
    "    ],\n",
    "    \"UPS\": [\n",
    "        \"UPS\", \"United Parcel Service\", \"$UPS\", \"#UPS\", \"Carol Tomé\"\n",
    "    ],\n",
    "    \"Centene\": [\n",
    "        \"Centene\", \"Centene Corp\", \"Centene Corporation\", \"CNC\", \"$CNC\", \"Sarah London\"\n",
    "    ],\n",
    "    \"Cigna\": [\n",
    "        \"Cigna\", \"The Cigna Group\", \"CI\", \"$CI\", \"David Cordani\"\n",
    "    ],\n",
    "    \"Microsoft\": [\n",
    "        \"Microsoft\", \"MSFT\", \"$MSFT\", \"#MSFT\", \"Satya Nadella\", \"Bill Gates\"\n",
    "    ],\n",
    "    \"Verizon\": [\n",
    "        \"Verizon\", \"Verizon Communications\", \"VZ\", \"$VZ\", \"Hans Vestberg\"\n",
    "    ],\n",
    "    \"IBM\": [\n",
    "        \"IBM\", \"International Business Machines\", \"$IBM\", \"#IBM\", \"Arvind Krishna\"\n",
    "    ],\n",
    "    \"UnitedHealth\": [\n",
    "        \"UnitedHealth\", \"UnitedHealth Group\", \"United Healthcare\", \"UnitedHealthcare\", \"UNH\", \"$UNH\", \"#UNH\", \"Stephen Hemsley\"\n",
    "    ],\n",
    "    \"ExxonMobil\": [\n",
    "        \"ExxonMobil\", \"Exxon Mobil Corporation\", \"XOM\", \"$XOM\", \"Darren Woods\"\n",
    "    ],\n",
    "    \"McKesson\": [\n",
    "        \"McKesson\", \"McKesson Corp\", \"McKesson Corporation\", \"MCK\", \"$MCK\", \"Brian Tyler\"\n",
    "    ],\n",
    "    \"Chevron\": [\n",
    "        \"Chevron\", \"CVX\", \"$CVX\", \"Michael Wirth\"\n",
    "    ],\n",
    "    \"Cardinal Health\": [\n",
    "        \"Cardinal Health\", \"CAH\", \"$CAH\", \"Jason Hollar\"\n",
    "    ],\n",
    "    \"Home Depot\": [\n",
    "        \"Home Depot\", \"The Home Depot\", \"HD\", \"$HD\", \"Ted Decker\"\n",
    "    ],\n",
    "    \"Walgreens Boots Alliance\": [\n",
    "        \"Walgreens Boots Alliance\", \"WBA\", \"$WBA\", \"Tim Wentworth\"\n",
    "    ],\n",
    "    \"Marathon Petroleum\": [\n",
    "        \"Marathon Petroleum\", \"MPC\", \"$MPC\", \"Michael Hennigan\"\n",
    "    ],\n",
    "    \"Elevance Health\": [\n",
    "        \"Elevance Health\", \"ANTM\", \"$ANTM\", \"Gail Boudreaux\"\n",
    "    ],\n",
    "    \"Ford\": [\n",
    "        \"Ford\", \"Ford Motor Company\", \"F\", \"$F\", \"Jim Farley\"\n",
    "    ],\n",
    "    \"AmerisourceBergen\": [\n",
    "        \"AmerisourceBergen\", \"ABC\", \"$ABC\", \"Steven Collis\"\n",
    "    ],\n",
    "    \"Dell Technologies\": [\n",
    "        \"Dell Technologies\", \"DELL\", \"$DELL\", \"Michael Dell\"\n",
    "    ],\n",
    "    \"General Motors\": [\n",
    "        \"General Motors\", \"GM\", \"$GM\", \"Mary Barra\"\n",
    "    ],\n",
    "    \"Nvidia\": [\n",
    "        \"Nvidia\", \"NVDA\", \"$NVDA\", \"Jensen Huang\"\n",
    "    ],\n",
    "    \"Pfizer\": [\n",
    "        \"Pfizer\", \"PFE\", \"$PFE\", \"Albert Bourla\"\n",
    "    ],\n",
    "    \"Procter & Gamble\": [\n",
    "        \"Procter & Gamble\", \"P&G\", \"PG\", \"$PG\", \"Jon Moeller\"\n",
    "    ],\n",
    "    \"Comcast\": [\n",
    "        \"Comcast\", \"CMCSA\", \"$CMCSA\", \"Brian Roberts\"\n",
    "    ],\n",
    "    \"Johnson & Johnson\": [\n",
    "        \"Johnson & Johnson\", \"J&J\", \"JNJ\", \"$JNJ\", \"Joaquin Duato\"\n",
    "    ],\n",
    "    \"Wells Fargo\": [\n",
    "        \"Wells Fargo\", \"WFC\", \"$WFC\", \"Charles Scharf\"\n",
    "    ],\n",
    "    \"Bank of America\": [\n",
    "        \"Bank of America\", \"BAC\", \"$BAC\", \"Brian Moynihan\"\n",
    "    ],\n",
    "    \"AbbVie\": [\n",
    "        \"AbbVie\", \"ABBV\", \"$ABBV\", \"Richard Gonzalez\"\n",
    "    ],\n",
    "    \"Caterpillar\": [\n",
    "        \"Caterpillar\", \"CAT\", \"$CAT\", \"Jim Umpleby\"\n",
    "    ],\n",
    "    \"Cisco\": [\n",
    "        \"Cisco\", \"Cisco Systems\", \"CSCO\", \"$CSCO\", \"Chuck Robbins\"\n",
    "    ],\n",
    "    \"AT&T\": [\n",
    "        \"AT&T\", \"T\", \"$T\", \"John Stankey\"\n",
    "    ],\n",
    "    \"PepsiCo\": [\n",
    "        \"PepsiCo\", \"PEP\", \"$PEP\", \"Ramon Laguarta\"\n",
    "    ],\n",
    "    \"Intel\": [\n",
    "        \"Intel\", \"INTC\", \"$INTC\", \"Pat Gelsinger\"\n",
    "    ],\n",
    "    \"The Walt Disney Company\": [\n",
    "        \"Disney\", \"The Walt Disney Company\", \"DIS\", \"$DIS\", \"Bob Iger\"\n",
    "    ],\n",
    "    \"Boeing\": [\n",
    "        \"Boeing\", \"BA\", \"$BA\", \"David Calhoun\"\n",
    "    ],\n",
    "    \"Goldman Sachs\": [\n",
    "        \"Goldman Sachs\", \"GS\", \"$GS\", \"David Solomon\"\n",
    "    ],\n",
    "    \"Morgan Stanley\": [\n",
    "        \"Morgan Stanley\", \"MS\", \"$MS\", \"Ted Pick\"\n",
    "    ],\n",
    "    \"Honeywell\": [\n",
    "        \"Honeywell\", \"Honeywell International\", \"HON\", \"$HON\", \"Vimal Kapur\"\n",
    "    ],\n",
    "    \"Salesforce\": [\n",
    "        \"Salesforce\", \"CRM\", \"$CRM\", \"Marc Benioff\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "TICKER_ALIASES = list1 = {\n",
    "    \"Walmart\": [\"Walmart\", \"#Walmart\", \"WMT\", \"$WMT\"],\n",
    "    \"Amazon\": [\"Amazon\", \"AMZN\", \"$AMZN\", \"#AMZN\", \"Amazon.com\"],\n",
    "    \"Apple\": [\"Apple\", \"AAPL\", \"$AAPL\", \"#AAPL\", \"Apple Inc\"],\n",
    "    \"CVS\": [\"CVS\", \"CVS Health\", \"CVS Pharmacy\", \"CVS Health Corp\", \"CVS Health Corporation\", \"$CVS\", \"#CVS\", \"CVS\"],\n",
    "    \"Tesla\": [\"Tesla\", \"TSLA\", \"$TSLA\", \"#TSLA\", \"Tesla Motors\"],\n",
    "    \"Google\": [\"Google\", \"Alphabet Inc\", \"GOOGL\", \"$GOOGL\", \"#GOOGL\"],\n",
    "    \"Meta\": [\"Meta\", \"Meta Platforms\", \"META\", \"$META\", \"#META\", \"Facebook\"],\n",
    "    \"JPMorgan\": [\"JPMorgan\", \"JP Morgan\", \"JPMorgan Chase\", \"JPMorgan Chase & Co.\", \"JPM\", \"$JPM\", \"#JPM\", \"Chase\", \"#Chase\"],\n",
    "    \"Costco\": [\"Costco\", \"Costco Wholesale\", \"COST\", \"$COST\"],\n",
    "    \"Kroger\": [\"Kroger\", \"The Kroger Co.\", \"KR\", \"$KR\"],\n",
    "    \"Walgreens\": [\"Walgreens\", \"WBA\", \"$WBA\"],\n",
    "    \"Target\": [\"Target\", \"TGT\", \"$TGT\"],\n",
    "    \"UPS\": [\"UPS\", \"United Parcel Service\", \"$UPS\", \"#UPS\"],\n",
    "    \"Centene\": [\"Centene\", \"Centene Corp\", \"Centene Corporation\", \"CNC\", \"$CNC\"],\n",
    "    \"Cigna\": [\"Cigna\", \"The Cigna Group\", \"CI\", \"$CI\"],\n",
    "    \"Microsoft\": [\"Microsoft\", \"MSFT\", \"$MSFT\", \"#MSFT\"],\n",
    "    \"Verizon\": [\"Verizon\", \"Verizon Communications\", \"VZ\", \"$VZ\"],\n",
    "    \"IBM\": [\"IBM\", \"International Business Machines\", \"$IBM\", \"#IBM\"],\n",
    "    \"UnitedHealth\": [\"UnitedHealth\", \"UnitedHealth Group\", \"United Healthcare\", \"UnitedHealthcare\", \"UNH\", \"$UNH\", \"#UNH\"],\n",
    "    \"ExxonMobil\": [\"ExxonMobil\", \"Exxon Mobil Corporation\", \"XOM\", \"$XOM\"],\n",
    "    \"McKesson\": [\"McKesson\", \"McKesson Corp\", \"McKesson Corporation\", \"MCK\", \"$MCK\"],\n",
    "    \"Chevron\": [\"Chevron\", \"CVX\", \"$CVX\"],\n",
    "    \"Cardinal Health\": [\"Cardinal Health\", \"CAH\", \"$CAH\"],\n",
    "    \"Home Depot\": [\"Home Depot\", \"The Home Depot\", \"HD\", \"$HD\"],\n",
    "    \"Walgreens Boots Alliance\": [\"Walgreens Boots Alliance\", \"WBA\", \"$WBA\"],\n",
    "    \"Marathon Petroleum\": [\"Marathon Petroleum\", \"MPC\", \"$MPC\"],\n",
    "    \"Elevance Health\": [\"Elevance Health\", \"ANTM\", \"$ANTM\"],\n",
    "    \"Ford\": [\"Ford\", \"Ford Motor Company\", \"F\", \"$F\"],\n",
    "    \"AmerisourceBergen\": [\"AmerisourceBergen\", \"ABC\", \"$ABC\"],\n",
    "    \"Dell Technologies\": [\"Dell Technologies\", \"DELL\", \"$DELL\"],\n",
    "    \"General Motors\": [\"General Motors\", \"GM\", \"$GM\"],\n",
    "    \"Nvidia\": [\"Nvidia\", \"NVDA\", \"$NVDA\"],\n",
    "    \"Pfizer\": [\"Pfizer\", \"PFE\", \"$PFE\"],\n",
    "    \"Procter & Gamble\": [\"Procter & Gamble\", \"P&G\", \"PG\", \"$PG\"],\n",
    "    \"Comcast\": [\"Comcast\", \"CMCSA\", \"$CMCSA\"],\n",
    "    \"Johnson & Johnson\": [\"Johnson & Johnson\", \"J&J\", \"JNJ\", \"$JNJ\"],\n",
    "    \"Wells Fargo\": [\"Wells Fargo\", \"WFC\", \"$WFC\"],\n",
    "    \"Bank of America\": [\"Bank of America\", \"BAC\", \"$BAC\"],\n",
    "    \"AbbVie\": [\"AbbVie\", \"ABBV\", \"$ABBV\"],\n",
    "    \"Caterpillar\": [\"Caterpillar\", \"CAT\", \"$CAT\"],\n",
    "    \"Cisco\": [\"Cisco\", \"Cisco Systems\", \"CSCO\", \"$CSCO\"],\n",
    "    \"AT&T\": [\"AT&T\", \"T\", \"$T\"],\n",
    "    \"PepsiCo\": [\"PepsiCo\", \"PEP\", \"$PEP\"],\n",
    "    \"Intel\": [\"Intel\", \"INTC\", \"$INTC\"],\n",
    "    \"The Walt Disney Company\": [\"Disney\", \"The Walt Disney Company\", \"DIS\", \"$DIS\"],\n",
    "    \"Boeing\": [\"Boeing\", \"BA\", \"$BA\"],\n",
    "    \"Goldman Sachs\": [\"Goldman Sachs\", \"GS\", \"$GS\"],\n",
    "    \"Morgan Stanley\": [\"Morgan Stanley\", \"MS\", \"$MS\"],\n",
    "    \"Honeywell\": [\"Honeywell\", \"Honeywell International\", \"HON\", \"$HON\"],\n",
    "    \"Salesforce\": [\"Salesforce\", \"CRM\", \"$CRM\"],\n",
    "}\n",
    "\n",
    "CEO_LIST = {\n",
    "    \"Walmart\": \"Doug McMillon\",\n",
    "    \"Amazon\": [\"Andy Jassy\", \"Jeff Bezos\"],\n",
    "    \"Apple\": \"Tim Cook\",\n",
    "    \"CVS\": \"David Joyner\",\n",
    "    \"Tesla\": \"Elon Musk\",\n",
    "    \"Google\": \"Sundar Pichai\",\n",
    "    \"Meta\": \"Mark Zuckerberg\",\n",
    "    \"JPMorgan\": \"Jamie Dimon\",\n",
    "    \"Costco\": \"Ron Vachris\",\n",
    "    \"Kroger\": \"Rodney McMullen\",\n",
    "    \"Walgreens\": \"Tim Wentworth\",\n",
    "    \"Target\": \"Brian Cornell\",\n",
    "    \"UPS\": \"Carol Tomé\",\n",
    "    \"Centene\": \"Sarah London\",\n",
    "    \"Cigna\": \"David Cordani\",\n",
    "    \"Microsoft\": [\"Satya Nadella\", \"Bill Gates\"],\n",
    "    \"Verizon\": \"Hans Vestberg\",\n",
    "    \"IBM\": \"Arvind Krishna\",\n",
    "    \"UnitedHealth\": \"Stephen Hemsley\",\n",
    "    \"ExxonMobil\": \"Darren Woods\",\n",
    "    \"McKesson\": \"Brian Tyler\",\n",
    "    \"Chevron\": \"Michael Wirth\",\n",
    "    \"Cardinal Health\": \"Jason Hollar\",\n",
    "    \"Home Depot\": \"Ted Decker\",\n",
    "    \"Walgreens Boots Alliance\": \"Tim Wentworth\",\n",
    "    \"Marathon Petroleum\": \"Michael Hennigan\",\n",
    "    \"Elevance Health\": \"Gail Boudreaux\",\n",
    "    \"Ford\": \"Jim Farley\",\n",
    "    \"AmerisourceBergen\": \"Steven Collis\",\n",
    "    \"Dell Technologies\": \"Michael Dell\",\n",
    "    \"General Motors\": \"Mary Barra\",\n",
    "    \"Nvidia\": \"Jensen Huang\",\n",
    "    \"Pfizer\": \"Albert Bourla\",\n",
    "    \"Procter & Gamble\": \"Jon Moeller\",\n",
    "    \"Comcast\": \"Brian Roberts\",\n",
    "    \"Johnson & Johnson\": \"Joaquin Duato\",\n",
    "    \"Wells Fargo\": \"Charles Scharf\",\n",
    "    \"Bank of America\": \"Brian Moynihan\",\n",
    "    \"AbbVie\": \"Richard Gonzalez\",\n",
    "    \"Caterpillar\": \"Jim Umpleby\",\n",
    "    \"Cisco\": \"Chuck Robbins\",\n",
    "    \"AT&T\": \"John Stankey\",\n",
    "    \"PepsiCo\": \"Ramon Laguarta\",\n",
    "    \"Intel\": \"Pat Gelsinger\",\n",
    "    \"The Walt Disney Company\": \"Bob Iger\",\n",
    "    \"Boeing\": \"David Calhoun\",\n",
    "    \"Goldman Sachs\": \"David Solomon\",\n",
    "    \"Morgan Stanley\": \"Ted Pick\",\n",
    "    \"Honeywell\": \"Vimal Kapur\",\n",
    "    \"Salesforce\": \"Marc Benioff\",\n",
    "}\n",
    "# ---------- HELPERS ----------\n",
    "def _parse_iso_created_at(maybe_iso: str) -> Optional[datetime]:\n",
    "    if not maybe_iso:\n",
    "        return None\n",
    "    try:\n",
    "        return datetime.fromisoformat(maybe_iso.replace(\"Z\", \"+00:00\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _post_created_at(post) -> Optional[datetime]:\n",
    "    try:\n",
    "        rec = getattr(post, \"record\", None)\n",
    "        if rec:\n",
    "            for name in (\"created_at\", \"createdAt\"):\n",
    "                val = getattr(rec, name, None)\n",
    "                if val:\n",
    "                    dt = _parse_iso_created_at(val)\n",
    "                    if dt:\n",
    "                        return dt\n",
    "    except Exception:\n",
    "        pass\n",
    "    for name in (\"created_at\", \"createdAt\"):\n",
    "        val = getattr(post, name, None)\n",
    "        if val:\n",
    "            dt = _parse_iso_created_at(val)\n",
    "            if dt:\n",
    "                return dt\n",
    "    return None\n",
    "\n",
    "def _get_post_uri(obj) -> Optional[str]:\n",
    "    \"\"\"Return a stable unique id for dedupe (SDK: .uri, HTTP: ['uri']).\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return obj.get(\"uri\")\n",
    "    return getattr(obj, \"uri\", None)\n",
    "\n",
    "def _date_range_last_n_days(days: int, today: Optional[date] = None) -> List[date]:\n",
    "    if today is None:\n",
    "        today = datetime.now(timezone.utc).date()\n",
    "    return [(today - timedelta(days=i)) for i in range(days, 0, -1)]\n",
    "\n",
    "def _normalize_term(term: str) -> str:\n",
    "    \"\"\"Wrap multi-word terms in quotes if not already.\"\"\"\n",
    "    t = term.strip()\n",
    "    if \" \" in t and not (t.startswith('\"') and t.endswith('\"')):\n",
    "        t = f'\"{t}\"'\n",
    "    return t\n",
    "\n",
    "def _q_for_day(base_q: str, day_utc: date) -> str:\n",
    "    \"\"\"Inject UTC window into q so the API only returns that day.\"\"\"\n",
    "    day1 = day_utc.isoformat()\n",
    "    day2 = (day_utc + timedelta(days=1)).isoformat()\n",
    "    return f'{base_q} since:{day1} until:{day2}'\n",
    "\n",
    "# ---------- RESILIENT SEARCH ----------\n",
    "_RETRYABLE_HTTP = {429, 500, 502, 503, 504}\n",
    "\n",
    "def _sdk_search(q: str, limit: int, cursor: Optional[str]) -> object:\n",
    "    params = {\"q\": q, \"limit\": limit}\n",
    "    if cursor:\n",
    "        params[\"cursor\"] = cursor\n",
    "    return client.app.bsky.feed.search_posts(params)\n",
    "\n",
    "def _http_search(q: str, limit: int, cursor: Optional[str]) -> dict:\n",
    "    params = {\"q\": q, \"limit\": limit}\n",
    "    if cursor:\n",
    "        params[\"cursor\"] = cursor\n",
    "    r = requests.get(f\"{APPVIEW_BASE}/xrpc/app.bsky.feed.searchPosts\", params=params, timeout=30)\n",
    "    if r.status_code in _RETRYABLE_HTTP:\n",
    "        r.raise_for_status()\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def _search_resilient(q: str, limit: int, cursor: Optional[str],\n",
    "                      sdk_tries: int = 3, http_tries: int = 3,\n",
    "                      backoff_base: float = 1.5):\n",
    "    \"\"\"\n",
    "    Try SDK with exponential backoff; on failure, fallback to HTTP with backoff.\n",
    "    Returns (posts, next_cursor, used_http: bool).\n",
    "    Posts are either SDK objects or dicts.\n",
    "    \"\"\"\n",
    "    # SDK\n",
    "    attempt = 0\n",
    "    while attempt < sdk_tries:\n",
    "        attempt += 1\n",
    "        try:\n",
    "            resp = _sdk_search(q, limit, cursor)\n",
    "            posts = getattr(resp, \"posts\", []) or []\n",
    "            next_cur = getattr(resp, \"cursor\", None)\n",
    "            return posts, next_cur, False\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            if any(code in msg for code in (\"429\", \"500\", \"502\", \"503\", \"504\", \"UpstreamFailure\")):\n",
    "                time.sleep(min(backoff_base ** attempt, 30))\n",
    "                continue\n",
    "            break\n",
    "\n",
    "    # HTTP\n",
    "    attempt = 0\n",
    "    while attempt < http_tries:\n",
    "        attempt += 1\n",
    "        try:\n",
    "            resp = _http_search(q, limit, cursor)\n",
    "            posts = (resp or {}).get(\"posts\") or []\n",
    "            next_cur = (resp or {}).get(\"cursor\")\n",
    "            return posts, next_cur, True\n",
    "        except requests.HTTPError as e:\n",
    "            status = getattr(e.response, \"status_code\", None)\n",
    "            if status in _RETRYABLE_HTTP:\n",
    "                time.sleep(min(backoff_base ** attempt, 30))\n",
    "                continue\n",
    "            raise\n",
    "        except requests.RequestException:\n",
    "            time.sleep(min(backoff_base ** attempt, 30))\n",
    "            continue\n",
    "\n",
    "    raise RuntimeError(\"Search failed after SDK and HTTP retries\")\n",
    "\n",
    "# ---------- CORE ----------\n",
    "def count_mentions_last_n_days_for_terms(\n",
    "    terms: List[str],\n",
    "    days: int = 365,\n",
    "    max_pages: int = 50,\n",
    "    per_request_limit: int = 100,\n",
    ") -> Counter:\n",
    "    \"\"\"\n",
    "    Count unique posts per day for a list of search terms (aliases).\n",
    "    - Queries each day with since:/until: in q\n",
    "    - Runs for each term, dedupes by post URI across terms and pages\n",
    "    \"\"\"\n",
    "    counts = Counter()\n",
    "    today = datetime.now(timezone.utc).date()\n",
    "    day_list = _date_range_last_n_days(days, today)\n",
    "\n",
    "    # Normalize terms (quote multi-word)\n",
    "    terms = [_normalize_term(t) for t in terms]\n",
    "\n",
    "    for d in day_list:\n",
    "        start_dt = datetime.combine(d, datetime.min.time(), tzinfo=timezone.utc)\n",
    "        end_dt = datetime.combine(d + timedelta(days=1), datetime.min.time(), tzinfo=timezone.utc)\n",
    "\n",
    "        seen_uris: set = set()\n",
    "        daily_total = 0\n",
    "\n",
    "        for base in terms:\n",
    "            cursor = None\n",
    "            pages = 0\n",
    "            q_day = _q_for_day(base, d)\n",
    "\n",
    "            while True:\n",
    "                if pages >= max_pages:\n",
    "                    break\n",
    "                pages += 1\n",
    "\n",
    "                try:\n",
    "                    posts, cursor, used_http = _search_resilient(q_day, per_request_limit, cursor)\n",
    "                except Exception:\n",
    "                    # Give up this term/day, move to next term\n",
    "                    break\n",
    "\n",
    "                if not posts:\n",
    "                    break\n",
    "\n",
    "                first = posts[0]\n",
    "                is_dict = isinstance(first, dict)\n",
    "\n",
    "                if is_dict:\n",
    "                    # HTTP\n",
    "                    for post in posts:\n",
    "                        uri = post.get(\"uri\")\n",
    "                        if not uri or uri in seen_uris:\n",
    "                            continue\n",
    "                        rec = post.get(\"record\") or {}\n",
    "                        dt = _parse_iso_created_at(rec.get(\"createdAt\") or rec.get(\"created_at\"))\n",
    "                        if dt and (start_dt <= dt < end_dt):\n",
    "                            seen_uris.add(uri)\n",
    "                            daily_total += 1\n",
    "                else:\n",
    "                    # SDK\n",
    "                    for post in posts:\n",
    "                        uri = _get_post_uri(post)\n",
    "                        if not uri or uri in seen_uris:\n",
    "                            continue\n",
    "                        dt = _post_created_at(post)\n",
    "                        if dt and (start_dt <= dt < end_dt):\n",
    "                            seen_uris.add(uri)\n",
    "                            daily_total += 1\n",
    "\n",
    "                if not cursor:\n",
    "                    break\n",
    "\n",
    "        counts[d] = daily_total\n",
    "\n",
    "    return counts\n",
    "\n",
    "def counts_for_companies(\n",
    "    companies: Iterable[str],\n",
    "    days: int = 365\n",
    ") -> Dict[str, Counter]:\n",
    "    out: Dict[str, Counter] = {}\n",
    "    for name in companies:\n",
    "        terms = COMPANY_ALIASES.get(name, [name])\n",
    "        out[name] = count_mentions_last_n_days_for_terms(terms, days=days)\n",
    "    return out\n",
    "\n",
    "def write_company_date_matrix_csv(\n",
    "    company_to_counts: Dict[str, Counter],\n",
    "    days: int,\n",
    "    save_dir: str,\n",
    "    filename_prefix: str = \"bluesky_counts_matrix\"\n",
    ") -> str:\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    today = datetime.now(timezone.utc).date()\n",
    "    start_day = today - timedelta(days=days)\n",
    "\n",
    "    dates = _date_range_last_n_days(days, today)\n",
    "    header = [\"company\"] + [d.isoformat() for d in dates]\n",
    "\n",
    "    filename = f\"{filename_prefix}_{start_day.strftime('%Y%m%d')}-{today.strftime('%Y%m%d')}.csv\"\n",
    "    path = os.path.join(save_dir, filename)\n",
    "\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for company, cnt in company_to_counts.items():\n",
    "            row = [company] + [cnt.get(d, 0) for d in dates]\n",
    "            writer.writerow(row)\n",
    "\n",
    "    return path\n",
    "\n",
    "# ---------- RUN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    DAYS = 365\n",
    "\n",
    "    company_counts = counts_for_companies(COMPANIES, days=DAYS)\n",
    "    csv_path = write_company_date_matrix_csv(company_counts, DAYS, SAVE_DIR)\n",
    "\n",
    "    print(f\"Saved matrix to: {csv_path}\\n\")\n",
    "\n",
    "    dates = _date_range_last_n_days(DAYS)\n",
    "    print(\"company,\", \", \".join(d.isoformat() for d in dates))\n",
    "    for c in COMPANIES:\n",
    "        cnt = company_counts.get(c, Counter())\n",
    "        row = [str(cnt.get(d, 0)) for d in dates]\n",
    "        print(f\"{c}, \" + \", \".join(row))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
